{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e769dc",
   "metadata": {},
   "source": [
    "# KG Structure\n",
    "The structure of the KG will consist of 4 types of Nodes: Concept, Topic, Subject and Standar.\n",
    "The edges between the nodes will be of 5 types: Standard to Subject, Subject to Topic, Topic to Topic, Topic to Concept, Prerequisite Edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25d22534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will be user Torch for this one\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim    #nn has backpropagation function and optim has optimization function\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7117285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Prasad\\MSIITM\\Research\\Dataset\\train\\pre_req_dataset\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2518af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"KaggleDataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36f96d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pre requisite</th>\n",
       "      <th>concept</th>\n",
       "      <th>pre requisite taxonomy</th>\n",
       "      <th>concept taxonomy</th>\n",
       "      <th>title 12</th>\n",
       "      <th>title 12.1</th>\n",
       "      <th>title 12.2</th>\n",
       "      <th>title 12.3</th>\n",
       "      <th>title 12.4</th>\n",
       "      <th>...</th>\n",
       "      <th>BOW 656</th>\n",
       "      <th>BOW 657</th>\n",
       "      <th>BOW 658</th>\n",
       "      <th>BOW 659</th>\n",
       "      <th>BOW 660</th>\n",
       "      <th>BOW 661</th>\n",
       "      <th>BOW 662</th>\n",
       "      <th>BOW 663</th>\n",
       "      <th>BOW 664</th>\n",
       "      <th>BOW 665</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Collection and Presentation of Data - II</td>\n",
       "      <td>Assumed Mean Method</td>\n",
       "      <td>IX&gt;&gt;Mathematics&gt;&gt;Statistics&gt;&gt;Graphical Represe...</td>\n",
       "      <td>X&gt;&gt;Mathematics&gt;&gt;Statistics&gt;&gt;Cumulative Frequen...</td>\n",
       "      <td>0.423383</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Frequency Polygon</td>\n",
       "      <td>Assumed Mean Method</td>\n",
       "      <td>IX&gt;&gt;Mathematics&gt;&gt;Statistics&gt;&gt;Graphical Represe...</td>\n",
       "      <td>X&gt;&gt;Mathematics&gt;&gt;Statistics&gt;&gt;Cumulative Frequen...</td>\n",
       "      <td>0.454223</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Mean</td>\n",
       "      <td>Assumed Mean Method</td>\n",
       "      <td>VII&gt;&gt;Mathematics&gt;&gt;Data Handling&gt;&gt;Median</td>\n",
       "      <td>X&gt;&gt;Mathematics&gt;&gt;Statistics&gt;&gt;Cumulative Frequen...</td>\n",
       "      <td>0.809664</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Angle Sum Property</td>\n",
       "      <td>Construction of a Similar Triangle</td>\n",
       "      <td>VII&gt;&gt;Mathematics&gt;&gt;The Triangle and its Propert...</td>\n",
       "      <td>X&gt;&gt;Mathematics&gt;&gt;Triangles&gt;&gt;Similar Figures</td>\n",
       "      <td>0.614234</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Inequality Property of Triangle</td>\n",
       "      <td>Construction of a Similar Triangle</td>\n",
       "      <td>VII&gt;&gt;Mathematics&gt;&gt;The Triangle and its Propert...</td>\n",
       "      <td>X&gt;&gt;Mathematics&gt;&gt;Triangles&gt;&gt;Similar Figures</td>\n",
       "      <td>0.739953</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 986 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                             pre requisite  \\\n",
       "0      1  Collection and Presentation of Data - II   \n",
       "1      1                         Frequency Polygon   \n",
       "2      1                                      Mean   \n",
       "3      0                        Angle Sum Property   \n",
       "4      0           Inequality Property of Triangle   \n",
       "\n",
       "                              concept  \\\n",
       "0                 Assumed Mean Method   \n",
       "1                 Assumed Mean Method   \n",
       "2                 Assumed Mean Method   \n",
       "3  Construction of a Similar Triangle   \n",
       "4  Construction of a Similar Triangle   \n",
       "\n",
       "                              pre requisite taxonomy  \\\n",
       "0  IX>>Mathematics>>Statistics>>Graphical Represe...   \n",
       "1  IX>>Mathematics>>Statistics>>Graphical Represe...   \n",
       "2            VII>>Mathematics>>Data Handling>>Median   \n",
       "3  VII>>Mathematics>>The Triangle and its Propert...   \n",
       "4  VII>>Mathematics>>The Triangle and its Propert...   \n",
       "\n",
       "                                    concept taxonomy  title 12  title 12.1  \\\n",
       "0  X>>Mathematics>>Statistics>>Cumulative Frequen...  0.423383           3   \n",
       "1  X>>Mathematics>>Statistics>>Cumulative Frequen...  0.454223           2   \n",
       "2  X>>Mathematics>>Statistics>>Cumulative Frequen...  0.809664           1   \n",
       "3         X>>Mathematics>>Triangles>>Similar Figures  0.614234           3   \n",
       "4         X>>Mathematics>>Triangles>>Similar Figures  0.739953           2   \n",
       "\n",
       "   title 12.2  title 12.3  title 12.4  ...  BOW 656  BOW 657  BOW 658  \\\n",
       "0    1.000000    1.000000    1.000000  ...        0        0        0   \n",
       "1    1.000000    1.000000    1.000000  ...        0        0        0   \n",
       "2    1.000000    1.000000    1.000000  ...        0        0        0   \n",
       "3    1.000000    1.000000    1.000000  ...        0        0        0   \n",
       "4    0.666667    0.666667    0.666667  ...        0        0        0   \n",
       "\n",
       "   BOW 659  BOW 660  BOW 661  BOW 662  BOW 663  BOW 664  BOW 665  \n",
       "0        0        0        0        0        0        0        0  \n",
       "1        0        0        0        0        0        0        0  \n",
       "2        0        0        0        0        0        0        0  \n",
       "3        0        0        0        0        0        0        0  \n",
       "4        0        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 986 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aca131",
   "metadata": {},
   "source": [
    "## Now let's create node set where we keep our concepts as nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9177f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_concept = set(x for x in data['concept'])\n",
    "for x in data['pre requisite']:\n",
    "    node_concept.add(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb490dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909\n"
     ]
    }
   ],
   "source": [
    "print(len(node_concept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e75cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the taxonomy into lists using lambda\n",
    "data['pre requisite taxonomy'] = data['pre requisite taxonomy'].apply(lambda x: x.split(\">>\"))\n",
    "data['concept taxonomy'] = data['concept taxonomy'].apply(lambda x: x.split(\">>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aff9cea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Apply a lambda function to calculate the maximum length of lists in the column\n",
    "print(data['pre requisite taxonomy'].apply(lambda x: len(x)).max())\n",
    "print(data['concept taxonomy'].apply(lambda x: len(x)).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af6febd",
   "metadata": {},
   "source": [
    "# Add standard nodes in the nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fff76d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_standard = set()\n",
    "for x in data['pre requisite taxonomy']:\n",
    "    node_standard.add(x[0])\n",
    "for x in data['concept taxonomy']:\n",
    "    node_standard.add(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26317243",
   "metadata": {},
   "source": [
    "# Add subject nodes in the nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "952e5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_subject = set()\n",
    "for x in data['pre requisite taxonomy']:\n",
    "    node_subject.add(x[1])\n",
    "for x in data['concept taxonomy']:\n",
    "    node_subject.add(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d22bab1",
   "metadata": {},
   "source": [
    "# Add topic nodes in the nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae6b0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_topic = set()\n",
    "for x in data['pre requisite taxonomy']:\n",
    "    node_topic.update(x[2:])\n",
    "\n",
    "for x in data['concept taxonomy']:\n",
    "    node_topic.update(x[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47daaf1",
   "metadata": {},
   "source": [
    "# Creating entity2id.csv, first row will represent the entity name and second will represent the id. IDs will be alphanumeric ids consisting of 3 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2eb1d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = list(node_topic | node_subject | node_standard | node_concept)\n",
    "entity2id = pd.DataFrame(all_entities, columns=['entities'])\n",
    "entity2id['id'] = range(0,len(entity2id))\n",
    "entity2id = entity2id[['id', 'entities']]\n",
    "entity2id.to_csv(\"entity2id.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cd079b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38899357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import string\n",
    "\n",
    "# # Combine all entity names into a single list\n",
    "# all_entities = list(node_topic | node_subject | node_standard | node_concept)\n",
    "\n",
    "# # Shuffle the entity names to randomize the order\n",
    "# random.shuffle(all_entities)\n",
    "\n",
    "# # Function to generate a random alphanumeric 3-digit ID\n",
    "# def generate_id():\n",
    "#     return ''.join(random.choices(string.ascii_uppercase + string.digits, k=3))\n",
    "\n",
    "# # Create the \"entity2id.txt\" file\n",
    "# with open(\"entity2id.txt\", \"w\") as file:\n",
    "#     # Write the number of entities as the first line\n",
    "#     file.write(f\"{len(all_entities)}\\n\")\n",
    "\n",
    "#     # Write header\n",
    "# #     file.write(\"EntityID\\tEntityName\\n\")\n",
    "\n",
    "#     # Write entity names and corresponding IDs\n",
    "#     for entity_name in all_entities:\n",
    "#         entity_id = generate_id()\n",
    "#         file.write(f\"{entity_name}\\t{entity_id}\\n\")\n",
    "\n",
    "# print(\"entity2id.txt file has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c76d3",
   "metadata": {},
   "source": [
    "# Now let's create relationship files\n",
    "Don't run this file again since we will use already created relationships in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "744c13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship = ['next standard of', 'is subject of standard', 'is topic of subject', 'is concept of topic', 'is prerequisite of']\n",
    "relationship2id = pd.DataFrame(relationship, columns=['relationship'])\n",
    "relationship2id['id'] = range(0,len(relationship2id))\n",
    "relationship2id = relationship2id[['id', 'relationship']]\n",
    "relationship2id.to_csv(\"relationship2id.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8debf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship = ['next standard of', 'is subject of standard', 'is topic of subject', 'is concept of topic', 'is prerequisite of']\n",
    "\n",
    "# # Function to generate a random alphanumeric 3-digit ID\n",
    "# def generate_id():\n",
    "#     return ''.join(random.choices(string.ascii_uppercase + string.digits, k=2))\n",
    "\n",
    "# # Create the \"entity2id.txt\" file\n",
    "# with open(\"relation2id.txt\", \"w\") as file:\n",
    "#     # Write the number of entities as the first line\n",
    "#     file.write(f\"{len(relationship)}\\n\")\n",
    "\n",
    "#     # Write header\n",
    "# #     file.write(\"EntityID\\tEntityName\\n\")\n",
    "\n",
    "#     # Write entity names and corresponding IDs\n",
    "#     for relation_name in relationship:\n",
    "#         relation_id = generate_id()\n",
    "#         file.write(f\"{relation_name}\\t{relation_id}\\n\")\n",
    "\n",
    "# print(\"relation2id.txt file has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4edb696",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_data_dict = pd.Series(entity2id['id'].values, index=entity2id['entities']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "164c28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to read the \"entity2id.txt\" file and store it in a dictionary\n",
    "# def read_entity2id_file(file_path):\n",
    "#     entity_data = {}\n",
    "\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         # Read the first line containing the number of entities\n",
    "#         num_entities = int(file.readline().strip())\n",
    "\n",
    "#         # Skip the header line\n",
    "# #         file.readline()\n",
    "\n",
    "#         # Read and store the data in the dictionary\n",
    "#         for _ in range(num_entities):\n",
    "#             line = file.readline().strip().split('\\t')\n",
    "#             entity_name, entity_id = line[0], line[1]\n",
    "#             entity_data[entity_name] = entity_id\n",
    "\n",
    "#     return entity_data\n",
    "\n",
    "# # Provide the path to your \"entity2id.txt\" file\n",
    "# file_path = \"entity2id.txt\"\n",
    "\n",
    "# # Call the function to read the file and store data in a dictionary\n",
    "# entity_data_dict = read_entity2id_file(file_path)\n",
    "\n",
    "# file_path = \"relation2id.txt\"\n",
    "# relation_data_dict = read_entity2id_file(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f7c14",
   "metadata": {},
   "source": [
    "# Creating training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46ece6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "# We add prerequisite relationship to the training data\n",
    "for index, x in data.iterrows():\n",
    "    if int(x['label']):\n",
    "        training_data.append((entity_data_dict[x['pre requisite']],entity_data_dict[x['concept']],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "128ff494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add 'is subject of standard' and 'is topic of subject relationship'\n",
    "for index, x in data.iterrows():\n",
    "        training_data.append((entity_data_dict[x['pre requisite taxonomy'][1]],entity_data_dict[x['pre requisite taxonomy'][0]],1))\n",
    "        training_data.append((entity_data_dict[x['concept taxonomy'][1]],entity_data_dict[x['concept taxonomy'][0]],1))\n",
    "        training_data.append((entity_data_dict[x['pre requisite taxonomy'][2]],entity_data_dict[x['pre requisite taxonomy'][1]],2))\n",
    "        training_data.append((entity_data_dict[x['concept taxonomy'][2]],entity_data_dict[x['concept taxonomy'][1]],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "850d0002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VII', 'IX', 'XII', 'VI', 'X', 'XI', 'VIII'}\n"
     ]
    }
   ],
   "source": [
    "# We add 'is next standard of' relationship\n",
    "\n",
    "#We take the unique standards available in the dataset\n",
    "stds = set(x[0] for x in data['pre requisite taxonomy'])\n",
    "for x in data['concept taxonomy']:\n",
    "    stds.add(x[0])\n",
    "\n",
    "print(stds)  # we have all the unique standards in stds set\n",
    "\n",
    "# Lets add them manually since we don't have exact relationship in the dataset, it is the domain knowledge.\n",
    "\n",
    "training_data.append((entity_data_dict['VII'],entity_data_dict['VI'],0))\n",
    "training_data.append((entity_data_dict['VIII'],entity_data_dict['VII'],0))\n",
    "training_data.append((entity_data_dict['IX'],entity_data_dict['VIII'],0))\n",
    "training_data.append((entity_data_dict['X'],entity_data_dict['IX'],0))\n",
    "training_data.append((entity_data_dict['XI'],entity_data_dict['X'],0))\n",
    "training_data.append((entity_data_dict['XII'],entity_data_dict['XI'],0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41e90a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12307"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14266819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add \"is concept of topic\"\n",
    "\n",
    "for index, x in data.iterrows():\n",
    "    tmp = x['pre requisite taxonomy'][2:]\n",
    "    for i in range(len(tmp)-1):\n",
    "        training_data.append((entity_data_dict[tmp[i+1]],entity_data_dict[tmp[i]],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2a1f958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15259"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f67141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = set()\n",
    "for row in training_data:\n",
    "    unique_values.add(row[0])\n",
    "    unique_values.add(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c11069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a27a41",
   "metadata": {},
   "source": [
    "# Export the training file in the CSV file so that we can use it directly without running whole code everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd95c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = pd.DataFrame(training_data)\n",
    "\n",
    "TrainingData.to_csv(\"TrainingData.csv\", index=False, header=[\"Head\",\"Tail\",\"Relation\"])\n",
    "TrainingData.to_csv(\"TrainingData.txt\", index=False, header=False)\n",
    "\n",
    "#add number of lines to the txt file in the first line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75feaaf1",
   "metadata": {},
   "source": [
    "# Now we have our training data ready, Lets create Knowledge Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb2b8cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0bb39548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Prasad\\MSIITM\\Research\\Dataset\\train\\pre_req_dataset\\NoteBooks\\OpenKE-OpenKE-PyTorch\\openke\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Prasad\\MSIITM\\Research\\Dataset\\train\\pre_req_dataset\\NoteBooks\\OpenKE-OpenKE-PyTorch\\openke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea52b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
